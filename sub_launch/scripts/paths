#!/usr/bin/env python

import argparse
import math
import time

import numpy

import roslib; roslib.load_manifest('sub_launch')
import rospy
import actionlib
from std_msgs.msg import Header
from geometry_msgs.msg import Pose, Quaternion, Point
from nav_msgs.msg import Odometry
from tf import transformations

from uf_common import orientation_helpers
from uf_common.msg import MoveToAction, MoveToGoal, PoseTwist
from uf_common.orientation_helpers import xyz_array, xyzw_array
from object_finder.msg import FindAction, FindGoal, TargetDesc


rospy.init_node('path')


visionclient = actionlib.SimpleActionClient('find_down', FindAction)
print 'Waiting for server...'
visionclient.wait_for_server()

DEPTH = .5
GO_RIGHT = True

client = actionlib.SimpleActionClient('moveto', MoveToAction)
print 'Waiting for server...'
client.wait_for_server()
print 'ok'

current = orientation_helpers.PoseEditor.from_PoseTwistStamped_topic('/trajectory').depth(DEPTH)
client.send_goal(current)

orig_orientation = current.orientation

went = False
ignore = False

def got_feedback(fb):
    global current, went, ignore
    obj_pose1 = orientation_helpers.PoseEditor.from_Pose(goal.header.frame_id, fb.targetreses[0].pose)
    # choose 180 deg rotation that minimizes difference from sub's original orientation
    obj_pose1 = max([obj_pose1, obj_pose1.turn_right_deg(180)],
        key=lambda p: p.orientation.dot(orig_orientation)**2)
    obj_pose2 = orientation_helpers.PoseEditor.from_Pose(goal.header.frame_id, fb.targetreses[1].pose)
    # choose 180 deg rotation that minimizes difference from sub's original orientation
    obj_pose2 = max([obj_pose2, obj_pose2.turn_right_deg(180)],
        key=lambda p: p.orientation.dot(orig_orientation)**2)
    
    if (orientation_helpers.quat_to_rotvec(transformations.quaternion_multiply(
            obj_pose1.orientation, transformations.quaternion_inverse(obj_pose2.orientation)))[2] < 0) ^ GO_RIGHT:
        obj_pose = obj_pose2
    else:
        obj_pose = obj_pose1
    
    if ignore: return
    print fb
    if (fb.P_within_10cm > .75 or went):
        # approach mode
        if not went:
            went = time.time()
        
        current = current.set_position(obj_pose.position).depth(DEPTH)
        current = current.set_orientation(obj_pose.orientation)
        print current.__dict__
        #current = current.set_position(obj_pose.position + obj_pose.forward_vector*2)
        #current = current.look_at(obj_pose.position)
        client.send_goal(current)
        if time.time() > went + 10:
            client.send_goal_and_wait(current)
            visionclient.cancel_goal()
            #client.send_goal_and_wait(current.forward(3))
            rospy.signal_shutdown('reached path')
    else:
        # search mode
        #current = current.look_at(obj_pose.position)
        #client.send_goal(current)
        pass

guess_pos = current.position + -current.body_up_vector * 3

targetdesc = TargetDesc()
targetdesc.type = TargetDesc.TYPE_OBJECT
targetdesc.object_filename = roslib.packages.resource_file('auvsi_robosub', 'models', '2012_uf_mock/path.obj')
targetdesc.prior_distribution.pose.position = Point(*guess_pos)
targetdesc.prior_distribution.pose.orientation.w = 1
targetdesc.prior_distribution.covariance[0+6*0] = 1
targetdesc.prior_distribution.covariance[1+6*1] = 1
targetdesc.prior_distribution.covariance[2+6*2] = 1
targetdesc.prior_distribution.covariance[5+6*5] = 100
targetdesc.min_dist = 3
targetdesc.max_dist = 5
targetdesc.is_180z_symmetric = True

goal = FindGoal()
goal.header.frame_id = current.header.frame_id
goal.targetdescs.append(targetdesc)
goal.targetdescs.append(targetdesc)
visionclient.send_goal(goal, feedback_cb=got_feedback)

#client.send_goal(current.forward(10).as_MoveToGoal(speed=.1))


rospy.spin()
